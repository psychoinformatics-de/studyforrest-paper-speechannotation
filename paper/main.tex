% For more detailed article preparation guidelines, please see:
% http://f1000research.com/author-guidelines
\documentclass[10pt,a4paper,onecolumn]{article}
\usepackage{f1000_styles}
\geometry{right=4cm}
\usepackage{booktabs}
\usepackage[
	colorlinks=true,
	urlcolor=blue,
	linkcolor=green
]{hyperref}
%% Default: numerical citations
\usepackage[numbers]{natbib}

%% Uncomment this lines for superscript citations instead
% \usepackage[super]{natbib}

%% Uncomment these lines for author-year citations instead
% \usepackage[round]{natbib}
% \let\cite\citep

\begin{document}
\input{descr-stats-anno.tex}
\input{descr-stats-regressors.tex}

\title{A studyforrest extension, an annotation of words and phonemes in the German dubbed movie ``Forrest Gump'' and its audio-description}
%\titlenote{whatever titlenote here}

% provide full affiliation information (including full institutional address, ZIP code and e-mail address) for all authors, and identify who is/are the corresponding author(s).
% EMAIL hier noch "kanonisch" unterbringen
% Madeburg habe ich nicht mit reingenommen, obwohl MD/Sachsen-Anhalt unten wg. Stipendium unter Funding kommt.
\author[1, 2]{Christian~O.~Häusler}
\author[1, 2]{Michael Hanke}

\affil[1]{Institute of Neuroscience and Medicine, Brain \& Behaviour (INM-7), Research Centre Jülich, Jülich, Germany}
\affil[2]{Institute of Systems Neuroscience, Medical Faculty, Heinrich Heine University, Düsseldorf, Germany}

\maketitle
\thispagestyle{fancy}
\begin{abstract}
% up to 300 words
Kommt ganz am Ende;
Intro, Method, Results, Discussion;
hier ggf. bereits Praat erwähnen;
im Gegensatz zu Sätzen und Phones haben Einzelworte zusätzliche Annos

\todo[inline]{The abstract should come now. It is needed to evaluate the
concept of the paper in the light of its content and vice versa.}

\end{abstract}
\section*{Keywords}
% maximal 8
language, speech, annotation, fMRI, natural stimulation, narrative, studyforrest

\listoftodos

\clearpage


\section*{Introduction}
% Links sind jetzt im laufenden Text; habs nach wie vor mit \href gemacht
% sieht bei längeren Links natürlich kacke aus

% largely adopted from haeusler2016annotation
% https://f1000research.com/articles/5-2273
% In Einleitung muss wohl noch etwas zu "reproducible research" und "datalad dataset" kommen
Cognitive neuroimaging research is moving towards studying brain behavior
under conditions of real-life(-like complexity). Motion pictures \citep{hasson2008neurocinematics} and continuous narratives \citep{honey2012not, lerner2011topographic} are increasingly utilized as so called naturalistic stimuli.

% new; not from haeusler2016annotation
Because naturalistic stimuli are multi-dimensional and their temporal structure
is (usually) unknown, data-driven methods like intersubject correlation
(ISC)\citep{hasson2004intersubject} or independent component analysis
(ICA)\citep{bartels2004chronoarchitecture} are often used to analyze
corresponding fMRI data. Nevertheless, theory-driven\todo{model-based?, there is little theroy in GLM} analyses like a general
linear model (GLM) are necessary to not just explain how but also when and why a
brain region is responding to a stimulus \citep{hamilton2018revolution}. Studies
using GLMs based on annotations of a stimulus' temporal structure have
elucidated how the brain responds to visual features of a movie
\citep{bartels2004mapping} or speech-related features of a narrative
\citep{rocca2019language}.

% adapted from haeusler2016annotation
% nun ja, folgend nicht super korrekt: sentences sind nicht vollständige
% Sätze im linguistischen Sinne (Subjekt, Objekt, Prädikat), sondern auch
% Ausrufe ("Forrest!") oder mitunter isolierte non-speech "Sätze" ("oouh").
% Sätze im linguistischen Sinne sind in der Annotation durch "." oder "?" am
% Ende gekennzeichnet. Sollte aber so passen.
For this publication, we annotated the onsets and offsets, and content of
sentences, single words, and phonemes spoken in the movie Forrest Gump (R.
Zemeckis, Paramount Pictures, 1994) \citep{ForrestGumpMovie}. fMRI data of
participants watching the audio-visual movie \citep{hanke2016simultaneous} and
it's audio-description for visually impaired persons \citep{hanke2014audiomovie}
are the core data of the publicly available \textit{studyforrest} dataset
(\href{www.studyforrest.org}{studyforrest.org}). Additional fMRI data
\citep{sengupta2016extension} include retinotopic mappings and localization of
higher visual areas of the same participants.
% paper regarding mention musical not mentioned
% und damit zitiere ich mich als dortiger Coauthor nicht selbst. Skandal!

The current annotation facilitates modelling of hemodynamic brain responses
correlating with speech-related events in the movie and audio-description.
Further, it extends already available annotations of portrayed emotions
\citep{labs2015portrayed} and perceived emtions
\citep{lettieri2019emotionotopy}, as well as cuts and locations depicted in the movie \citep{haeusler2016annotation}. All annotations can be used in any study focusing on other aspects of real-life cognition by serving as additional
confound measures describing key properties of major building blocks of the stimulus.

\section*{Materials and methods}
\subsection*{Stimulus}
% References sind vom Anno-Paper in die .bib-Datei übernommen worden; die
% “hardcoded” Zitationen sind aber noch im laufenden Text.
We annotated speech in the slightly shortened ``research cut'' of the movie
\citep{hanke2016simultaneous} and its temporally aligned audio-description
\citep{hanke2014audiomovie}. For the movie stimulus, we used the audio track of
the German DVD release (Paramount Home Entertainment, Germany, 2002; PAL video,
DE103519SV)\citep{ForrestGumpDVD}. For the audio-only stimulus, we used the
movie's audio-description that was broadcast as an additional audio track for
visually impaired listeners on Swiss public television (Koop, Michalski,
Beckmann, Meinhardt \& Benecke, produced by Bayrischer Rundfunk,
2009)\citep{ForrestGumpGermanAD}. The plot of the movie is already carried by an
off-screen voice of the main character Forrest Gump. In the largely identical audio-description, a male narrator additionally describes essential aspects of the visual scenery when there is no off-screen voice, dialog, or other relevant auditory content
\subsection*{Annotation procedure}
% wo kommen die "preliminaries transcriptions" her?
% Die "most basic" Datei, die das Dataset enthält ist der Merge aus Diaolog, Narrator & Non-Speech-Annotation
Preliminary, orthographic transcriptions of dialogues (german\_dialog.csv),
non-speech vocalizations (e.g. laughing or groaning;
non\_speech\_vocalization.json), and the audio-description's narrator
(german\_audio\_description.csv) were merged and converted to Praat's
\citep{boersma2019praat} .TextGrid format (
\href{www.fon.hum.uva.nl/praat}{fon.hum.uva.nl/praat}). The merged transcription
containing one onset and offset for usually a couple of sentences was opened
along (the audio file of) the audio-description in Praat v6.0.22 for manual
improvements: In several passes, the approximate temporal onsets and offsets
were corrected. Intervals containing several sentences were split into intervals
containing only one sentence. When two or more persons were speaking
simultaneously the less dominant (background) voice was dropped. Low volume
background speech (especially occurring during music or continuous environmental
noise) or low volume non-speech vocalizations that are difficult to recognize by
a regular audience were dropped, too.

% Alignment preparations
We used the Montreal Forced Aligner v1.0.1
\href{montrealcorpustools.github.io/Montreal-Forced-Aligner}{montrealcorpustools.github.io/Montreal-Forced-Aligner}\citep{mcauliffe2017montreal};to
algorithmically identify the onset and offset of each word and phoneme embedded
in the transcribed sentences. To enable the aligner to look up the pronunciation
of every word, we chose a German pronunciation dictionary
\href{https://raw.githubusercontent.com/prosodylab/prosodylab.dictionaries/master/de.dict}{raw.githubusercontent.com/prosodylab/prosodylab.dictionaries/master/de.dict}
provided by Prosodylab (\href{http://prosodylab.org}{prosodylab.org}) that uses
the Prosodylab PhoneSet. The dictionary was manually updated with movie-specific
German words. The pronunciation of English words occurring in the otherwise
German audio track was taken from an English pronunciation dictionary
(\href{http://mlmlab.org/mfa/dictionaries/english.dict}{mlmlab.org/mfa/dictionaries/english.dict} that uses the ARPAbet PhoneSet.

% Alignment
% Nicht erwähnt: Wenn die Korrektur der Phoneme unmöglich war, habe ich einfach
% die Event-Borders zwischen den Phonemen herausgenommen. Wortbeginn und Wortende stimmen dann mit einem neuen, "künstlich-großen Phoneme" überein.
% Das "Groß-Phonem" enthält dann ohne Grenzen zwischen den tatsächlichen Phonemen des Wortes alle Phoneme des Wortes ("es ist kompliziert zu erklären, aber im Grunde ganz einfach).
% kommt selten vor, ist im Grunde "noise" und ist in der Anno sofort als solches zu erkennen.
The audio file was converted from .FLAC to .WAV via ffmpeg v4.1.4
(\href{www.ffmpeg.org}{ffmpeg.org}) to meet the aligner's requirements. This
.WAV file, the transcription of sentences, and the updated dictionary were
submitted to the aligner that first trained an acoustic model on the data and
then performed the alignment. In a first step, the resulting .TextGrid file that
contains onsets and offsets of words and phonemes was opened in Praat to check
and correct the automatic alignment. In several passes, words [and their
corresponding phonemes] on which the automatic alignment performed moderately
were corrected. Some (low volume) sentences that are spoken in continuously
noisy settings (pursuit, battle, hurricane, demonstration/rally, disco) were
removed due to poor overall alignment performance. In a second step, the
complete sentences of the orthographic transcription were copied into the
annotation (s. table \ref{tab:overview} for an overview of the annotation's content). In a third step, the name of the speaker was added for every sentence (s. table \ref{tab:speakers} for the most often occurring speakers).
During every new step results from all previous steps were checked again for errors and corrected.

\begin{table*}[tbp]
\caption{Overview of the speech annotation's content for the whole stimulus and it's individual segments. The label ``Sentences''' comprises complete grammatical sentences (i.e. having a subject and a predicate, and additionally marked with a full stop in the annotation). The  ``Sentences'' also comprises exlamations or non-speech vocalizations in quick succession (e.g. ``ha, ha, ha'') or in isolation (e.g. ``ha'', at time points when speakers rapidly switch). The label ``Words'' comprises every single word or non-speech vocalization (N=\aPosNonspeechAll) in isolation.}
\label{tab:overview}
\begin{tabular}{llllllllll}
\toprule
\textbf{label} & \textbf{all} & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5} & \textbf{6} & \textbf{7} & \textbf{8}\\
\midrule
sentences  & \aSentencesAll & \aSentencesI & \aSentencesII & \aSentencesIII & \aSentencesIV & \aSentencesV & \aSentencesVI & \aSentencesVII & \aSentencesVIII \tabularnewline
words  & \aWordsAll & \aWordsI & \aWordsII & \aWordsIII & \aWordsIV & \aWordsV & \aWordsVI & \aWordsVII & \aWordsVIII \tabularnewline
phonemes  & \aPhonesAll & \aPhonesI & \aPhonesII & \aPhonesIII & \aPhonesIV & \aPhonesV & \aPhonesVI & \aPhonesVII & \aPhonesVIII \tabularnewline
\bottomrule
\end{tabular}
\end{table*}

% bei ein paar Namen bin ich ggf. von Labs abgewichen (genauer identifiziert, ggf. kleine Fehler korrigiert. Ist dann aber nur bei Personen, die 1-2x mit 1-2 Sätzen auftauchen.
\begin{table*}[btp]
\caption{Sentences spoken by the ten most often occurring speakers sorted alphabetically. The narrator only occurrs in the audio-description of the movie. Shown names are identical to the names used in \citep{labs2015portrayed}. Overall 97 persons were identified.}
\label{tab:speakers}
\begin{tabular}{llllllllll}
\toprule
\textbf{name} & \textbf{all} & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5} & \textbf{6} & \textbf{7} & \textbf{8}\\
\midrule
Bubba  & \aBubbaAll & \aBubbaI & \aBubbaII & \aBubbaIII & \aBubbaIV & \aBubbaV & \aBubbaVI & \aBubbaVII & \aBubbaVIII \tabularnewline
Forrest  & \aForrestAll & \aForrestI & \aForrestII & \aForrestIII & \aForrestIV & \aForrestV & \aForrestVI & \aForrestVII & \aForrestVIII \tabularnewline
Forrest (child)  & \aForrestchildAll & \aForrestchildI & \aForrestchildII & \aForrestchildIII & \aForrestchildIV & \aForrestchildV & \aForrestchildVI & \aForrestchildVII & \aForrestchildVIII \tabularnewline
Forrest (v.o.)  & \aForrestvoAll & \aForrestvoI & \aForrestvoII & \aForrestvoIII & \aForrestvoIV & \aForrestvoV & \aForrestvoVI & \aForrestvoVII & \aForrestvoVIII \tabularnewline
Hancock  & \aHancockAll & \aHancockI & \aHancockII & \aHancockIII & \aHancockIV & \aHancockV & \aHancockVI & \aHancockVII & \aHancockVIII \tabularnewline
Jenny  & \aJennyAll & \aJennyI & \aJennyII & \aJennyIII & \aJennyIV & \aJennyV & \aJennyVI & \aJennyVII & \aJennyVIII \tabularnewline
Jenny (child)  & \aJennychildAll & \aJennychildI & \aJennychildII & \aJennychildIII & \aJennychildIV & \aJennychildV & \aJennychildVI & \aJennychildVII & \aJennychildVIII \tabularnewline
Lt. Dan  & \aLtdanAll & \aLtdanI & \aLtdanII & \aLtdanIII & \aLtdanIV & \aLtdanV & \aLtdanVI & \aLtdanVII & \aLtdanVIII \tabularnewline
Mrs. Gump  & \aMrsgumpAll & \aMrsgumpI & \aMrsgumpII & \aMrsgumpIII & \aMrsgumpIV & \aMrsgumpV & \aMrsgumpVI & \aMrsgumpVII & \aMrsgumpVIII \tabularnewline
Narrator  & \aNarratorAll & \aNarratorI & \aNarratorII & \aNarratorIII & \aNarratorIV & \aNarratorV & \aNarratorVI & \aNarratorVII & \aNarratorVIII \tabularnewline
\bottomrule
\end{tabular}
\end{table*}



% descriptive Nouns
% hier ggf. noch angeben, dass die effektiv identisch waren
% Florian hat zwei Regeln falsch verstanden, sonst war übereinstimmung >90%
A further annotation of the audio-description's narrator was done manually: Two
persons performed a categorization of nouns embedded in sentences spoken by the
narrator to describe the movie's missing visual content. Categories focus on the
cinematographic scene's environment, inherent objects, persons, and a person's
appearance. A preliminary annotation according to the rules (s. ist jetzt in der obigen Tabelle aus Platzgründen nicht mehr drin; in dieser,\ref{tab:descr-nouns}, einer neuen Tabelle oder im laufenden Text [wird viel Text] bringen) was done by one person and corrected in several runs by the author.\todo{I thought we said that this aspect should move to the PPA paper?}

\begin{table*}[t]
    \caption{Narrator's descriptive nouns. All categories sorted alphapetically. Examples are given in English. Description (of rules) fehlt in dieser Tabelle (vgl. alte Tabelle auf der allerletzten Seite). Wird nämlich in einer Tabelle mit horizontaler Ausrichtung eng. Kategorie ``++'' enthält ausnahmesweise auch adverbiale Best. der Zeit.}
\label{tab:descr-nouns}
\begin{tabular}{lllllllllll}
\toprule
\textbf{label} & \textbf{examples} & \textbf{all} & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5} & \textbf{6} & \textbf{7} & \textbf{8} \\
\midrule
body & back, hip, shoulder; jacket, dress, shirt & \aDescrBodyAll & \aDescrBodyI & \aDescrBodyII & \aDescrBodyIII & \aDescrBodyIV & \aDescrBodyV & \aDescrBodyVI & \aDescrBodyVII & \aDescrBodyVIII \tabularnewline
bodypart  & arm, finger, leg, toe & \aDescrBodypartAll & \aDescrBodypartI & \aDescrBodypartII & \aDescrBodypartIII & \aDescrBodypartIV & \aDescrBodypartV & \aDescrBodypartVI & \aDescrBodypartVII & \aDescrBodypartVIII\tabularnewline
face & face, ear, nose, mouth & \aDescrFaceAll & \aDescrFaceI & \aDescrFaceII & \aDescrFaceIII & \aDescrFaceIV & \aDescrFaceV & \aDescrFaceVI & \aDescrFaceVII & \aDescrFaceVIII \tabularnewline
female & nurse, mother, woman & \aDescrFemaleAll & \aDescrFemaleI & \aDescrFemaleII & \aDescrFemaleIII & \aDescrFemaleIV & \aDescrFemaleV & \aDescrFemaleVI & \aDescrFemaleVII & \aDescrFemaleVIII \tabularnewline
females & women & \aDescrFemalesAll & \aDescrFemalesI & \aDescrFemalesII & \aDescrFemalesIII & \aDescrFemalesIV & \aDescrFemalesV & \aDescrFemalesVI & \aDescrFemalesVII & \aDescrFemalesVIII \tabularnewline
fname & Jenny & \aDescrFnameAll & \aDescrFnameI & \aDescrFnameII & \aDescrFnameIII & \aDescrFnameIV & \aDescrFnameV & \aDescrFnameVI & \aDescrFnameVII & \aDescrFnameVIII \tabularnewline
furniture & bench, bed, table, chair & \aDescrFurnitureAll & \aDescrFurnitureI & \aDescrFurnitureII & \aDescrFurnitureIII & \aDescrFurnitureIV & \aDescrFurnitureV & \aDescrFurnitureVI & \aDescrFurnitureVII & \aDescrFurnitureVIII \tabularnewline
geo & building, tree, street, alley, meadow, cornfield, river & \aDescrGeoAll & \aDescrGeoI & \aDescrGeoII & \aDescrGeoIII & \aDescrGeoIV & \aDescrGeoV & \aDescrGeoVI & \aDescrGeoVII & \aDescrGeoVIII \tabularnewline
geo-room & living room; wall, door, window, floor, turf & \aDescrGeoroomAll & \aDescrGeoroomI & \aDescrGeoroomII & \aDescrGeoroomIII & \aDescrGeoroomIV & \aDescrGeoroomV & \aDescrGeoroomVI & \aDescrGeoroomVII & \aDescrGeoroomVIII \tabularnewline
head & head, hair, ear, neck, helmet & \aDescrHeadAll & \aDescrHeadI & \aDescrHeadII & \aDescrHeadIII & \aDescrHeadIV & \aDescrHeadV & \aDescrHeadVI & \aDescrHeadVII & \aDescrHeadVIII \tabularnewline
male & man, father, soldier & \aDescrMaleAll & \aDescrMaleI & \aDescrMaleII & \aDescrMaleIII & \aDescrMaleIV & \aDescrMaleV & \aDescrMaleVI & \aDescrMaleVII & \aDescrMaleVIII \tabularnewline
males & boys, opponents & \aDescrMalesAll & \aDescrMalesI & \aDescrMalesII & \aDescrMalesIII & \aDescrMalesIV & \aDescrMalesV & \aDescrMalesVI & \aDescrMalesVII & \aDescrMalesVIII \tabularnewline
mname & Bubba, Kennedy & \aDescrMnameAll & \aDescrMnameI & \aDescrMnameII & \aDescrMnameIII & \aDescrMnameIV & \aDescrMnameV & \aDescrMnameVI & \aDescrMnameVII & \aDescrMnameVIII \tabularnewline
object & telephone, car & \aDescrObjectAll & \aDescrObjectI & \aDescrObjectII & \aDescrObjectIII & \aDescrObjectIV & \aDescrObjectV & \aDescrObjectVI & \aDescrObjectVII & \aDescrObjectVIII \tabularnewline
objects & wheels, photos & \aDescrObjectsAll & \aDescrObjectsI & \aDescrObjectsII & \aDescrObjectsIII & \aDescrObjectsIV & \aDescrObjectsV & \aDescrObjectsVI & \aDescrObjectsVII & \aDescrObjectsVIII \tabularnewline
persons & hippies, patients & \aDescrPersonsAll & \aDescrPersonsI & \aDescrPersonsII & \aDescrPersonsIII & \aDescrPersonsIV & \aDescrPersonsV & \aDescrPersonsVI & \aDescrPersonsVII & \aDescrPersonsVIII \tabularnewline
setting\_new & on a ``bridge'', on an ``alley'', on ``campus'' & \aDescrSettingnewAll & \aDescrSettingnewI & \aDescrSettingnewII & \aDescrSettingnewIII & \aDescrSettingnewIV & \aDescrSettingnewV & \aDescrSettingnewVI & \aDescrSettingnewVII & \aDescrSettingnewVIII \tabularnewline
setting\_rec & at the ``bus stop'' & \aDescrSettingrecAll & \aDescrSettingrecI & \aDescrSettingrecII & \aDescrSettingrecIII & \aDescrSettingrecIV & \aDescrSettingrecV & \aDescrSettingrecVI & \aDescrSettingrecVII & \aDescrSettingrecVIII \tabularnewline
++ &  in the ``evening'', it's ``daytime'', ``later'' & \aDescrAll & \aDescrI & \aDescrII & \aDescrIII & \aDescrIV & \aDescrV & \aDescrVI & \aDescrVII & \aDescrVIII \tabularnewline
\bottomrule
\end{tabular}
\todo[inline]{If the descriptive nounes are moved to the PPA paper, this table should be removed}
\end{table*}


% NLP
To automatically analyze linguistic features of words in their corresponding
sentence, we employed the Python package spaCy v2.2.1
(\href{https://spacy.io}{spacy.io}) and a German language model
(de\_core\_news\_md; \href{https://spacy.io/models/de}{spacy.io/models/de})
trained on the TIGER Treebank corpus
(\href{https://www.ims.uni-stuttgart.de}{ims.uni-stuttgart.de}). We performed
analyses regarding part of speech (i.e. grammatical tagging or word-category
disambiguation), syntactic dependency, lemmatization, word embedding (i.e.
semantic similarity), and if the word is one of the most common words of the
German language. Results of these analyzes were added to the annotation and
saved as .TextGrid file. This .TextGrid file was converted via python script to
a tab separated file in accordance with the brain imaging data structure
(\href{https://bids.neuroimaging.io/}{BIDS}\citep{gorgolewski2016bids}). Non-speech vocalizations were dropped from the sentences before analysis.
% BIDS stuff runter zu "Dataset content"?

\subsection*{Data Legend}
% wo wurde automatisch korrigiert (e.g. NE/NN, NONSPEECH)
% s. dictionaries oben in add_part-of-speech-tagging2textgrid.py

\subsubsection*{Start (\texttt{start})}
the onset of the sentences, word or phoneme provided in seconds of stimulus onset.

\subsubsection*{Duration (\texttt{end})}
the duration of the sentences, word or phoneme provided in seconds.

\subsubsection*{Speaker identity (\texttt{person})}
name of the persons that speaks the sentence, word or phoneme (s. table \ref{tab:speakers}).

% einige Eigennamen (NE/NN) wurden automatisch korrigiert, weil das Sprachmodell
% die naheliegenderweise nicht kannte; eine Liste dieser Eigennamen befindet
% sich oben in dem entsprechendem Skript
% (add_part-of-speech-tagging2textgrid.py)
\subsubsection*{Simple part-of-speech tag (\texttt{pos})}
This column contains tags for whole sentences ("SENTENCE"), phonemes ("PHONEME") and non-speech vocalizations (NONSPEECH). For single words, it contains a simple part-of-speech tagging (grammatical tagging; word-category disambiguation) taking the relationship with adjacent and related words in the same sentence into account (s. table \ref{tab:pos}). This simple part-of-speech tagging tags follow the \href{https://universaldependencies.org}{Universal Dependencies} v2 POS tag set.

\begin{table*}[t]
\caption{Simple part of speech tagging (POS). All 15 labels sorted alpapetically. Descriptions were taken from spaCy.explain(). Non-speech vocalizations (NONSPEECH) were manually identified.}
\label{tab:pos}
\begin{tabular}{lllllllllll}
\toprule
\textbf{label} & \textbf{description} & \textbf{all} & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5} & \textbf{6} & \textbf{7} & \textbf{8} \\
\midrule
ADJ & \aPosAdj & \aPosAdjAll & \aPosAdjI & \aPosAdjII & \aPosAdjIII & \aPosAdjIV & \aPosAdjV & \aPosAdjVI & \aPosAdjVII \tabularnewline
ADP & \aPosAdp & \aPosAdpAll & \aPosAdpI & \aPosAdpII & \aPosAdpIII & \aPosAdpIV & \aPosAdpV & \aPosAdpVI & \aPosAdpVII & \aPosAdpVIII \tabularnewline
ADV & \aPosAdv & \aPosAdvAll & \aPosAdvI & \aPosAdvII & \aPosAdvIII & \aPosAdvIV & \aPosAdvV & \aPosAdvVI & \aPosAdvVII & \aPosAdvVIII \tabularnewline
AUX & \aPosAux & \aPosAuxAll & \aPosAuxI & \aPosAuxII & \aPosAuxIII & \aPosAuxIV & \aPosAuxV & \aPosAuxVI & \aPosAuxVII & \aPosAuxVIII \tabularnewline
CONJ & \aPosConj & \aPosConjAll & \aPosConjI & \aPosConjII & \aPosConjIII & \aPosConjIV & \aPosConjV & \aPosConjVI & \aPosConjVII & \aPosConjVIII \tabularnewline
DET & \aPosDet & \aPosDetAll & \aPosDetI & \aPosDetII & \aPosDetIII & \aPosDetIV & \aPosDetV & \aPosDetVI & \aPosDetVII & \aPosDetVIII \tabularnewline
NONSPEECH & non-speech vocalization & \aPosNonspeechAll & \aPosNonspeechI & \aPosNonspeechII & \aPosNonspeechIII & \aPosNonspeechIV & \aPosNonspeechV & \aPosNonspeechVI & \aPosNonspeechVII & \aPosNonspeechVIII \tabularnewline
NOUN & \aPosNoun & \aPosNounAll & \aPosNounI & \aPosNounII & \aPosNounIII & \aPosNounIV & \aPosNounV & \aPosNounVI & \aPosNounVII & \aPosNounVIII \tabularnewline
NUM & \aPosNum & \aPosNumAll & \aPosNumI & \aPosNumII & \aPosNumIII & \aPosNumIV & \aPosNumV & \aPosNumVI & \aPosNumVII & \aPosNumVIII \tabularnewline
PART & \aPosPart & \aPosPartAll & \aPosPartI & \aPosPartII & \aPosPartIII & \aPosPartIV & \aPosPartV & \aPosPartVI & \aPosPartVII & \aPosPartVIII \tabularnewline
PRON & \aPosPron & \aPosPronAll & \aPosPronI & \aPosPronII & \aPosPronIII & \aPosPronIV & \aPosPronV & \aPosPronVI & \aPosPronVII & \aPosPronVIII \tabularnewline
PRON & \aPosPropn & \aPosPropnAll & \aPosPropnI & \aPosPropnII & \aPosPropnIII & \aPosPropnIV & \aPosPropnV & \aPosPropnVI & \aPosPropnVII & \aPosPropnVIII \tabularnewline
SCONJ & \aPosSconj & \aPosSconjAll & \aPosSconjI & \aPosSconjII & \aPosSconjIII & \aPosSconjIV & \aPosSconjV & \aPosSconjVI & \aPosSconjVII & \aPosSconjVIII \tabularnewline
VERB & \aPosVerb & \aPosVerbAll & \aPosVerbI & \aPosVerbII & \aPosVerbIII & \aPosVerbIV & \aPosVerbV & \aPosVerbVI & \aPosVerbVII & \aPosVerbVIII \tabularnewline
X & \aPosX & \aPosXAll & \aPosXI & \aPosXII & \aPosXIII & \aPosXIV & \aPosXV & \aPosXVI & \aPosXVII & \aPosXVIII \tabularnewline
\bottomrule
\end{tabular}
\end{table*}


\subsubsection*{Detailed part-of-speech tag (\texttt{tag})}
A detailed part-of-speech tagging following the TIGER Treebank annotation scheme \citep{brants2004tiger}(s. table \ref{tab:tag}) which is based on the \href{https://www.ims.uni-stuttgart.de/forschung/ressourcen/lexika/germantagsets}{Stuttgart-Tübingen-Tagset} \citep{schiller1999stts}.

\begin{table*}[t]
\caption{Detailed part of speech tagging (TAG). The 15 most often occurring labels (overall 43 labels) sorted alphabetically. Descriptions were taken from spaCy.explain().}
\label{tab:tag}
\begin{tabular}{lllllllllll}
\toprule
\textbf{label} & \textbf{description} & \textbf{all} & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5} & \textbf{6} & \textbf{7} & \textbf{8} \\
\midrule
ADJA & \aTagAdja & \aTagAdjaAll & \aTagAdjaI & \aTagAdjaII & \aTagAdjaIII & \aTagAdjaIV & \aTagAdjaV & \aTagAdjaVI & \aTagAdjaVII & \aTagAdjaVIII \tabularnewline
ADJD & \aTagAdjd & \aTagAdjdAll & \aTagAdjdI & \aTagAdjdII & \aTagAdjdIII & \aTagAdjdIV & \aTagAdjdV & \aTagAdjdVI & \aTagAdjdVII & \aTagAdjdVIII \tabularnewline
ADV & \aTagAdv & \aTagAdvAll & \aTagAdvI & \aTagAdvII & \aTagAdvIII & \aTagAdvIV & \aTagAdvV & \aTagAdvVI & \aTagAdvVII & \aTagAdvVIII \tabularnewline
APPR & \aTagAppr & \aTagApprAll & \aTagApprI & \aTagApprII & \aTagApprIII & \aTagApprIV & \aTagApprV & \aTagApprVI & \aTagApprVII & \aTagApprVIII \tabularnewline
ART & \aTagArt & \aTagArtAll & \aTagArtI & \aTagArtII & \aTagArtIII & \aTagArtIV & \aTagArtV & \aTagArtVI & \aTagArtVII & \aTagArtVIII \tabularnewline
KON & \aTagKon & \aTagKonAll & \aTagKonI & \aTagKonII & \aTagKonIII & \aTagKonIV & \aTagKonV & \aTagKonVI & \aTagKonVII & \aTagKonVIII \tabularnewline
NE & \aTagNe & \aTagNeAll & \aTagNeI & \aTagNeII & \aTagNeIII & \aTagNeIV & \aTagNeV & \aTagNeVI & \aTagNeVII & \aTagNeVIII \tabularnewline
NN & \aTagNn & \aTagNnAll & \aTagNnI & \aTagNnII & \aTagNnIII & \aTagNnIV & \aTagNnV & \aTagNnVI & \aTagNnVII & \aTagNnVIII \tabularnewline
PPER & \aTagPper & \aTagPperAll & \aTagPperI & \aTagPperII & \aTagPperIII & \aTagPperIV & \aTagPperV & \aTagPperVI & \aTagPperVII & \aTagPperVIII \tabularnewline
PPOSAT & \aTagPposat & \aTagPposatAll & \aTagPposatI & \aTagPposatII & \aTagPposatIII & \aTagPposatIV & \aTagPposatV & \aTagPposatVI & \aTagPposatVII & \aTagPposatVIII \tabularnewline
PTKVZ & \aTagPtkvz & \aTagPtkvzAll & \aTagPtkvzI & \aTagPtkvzII & \aTagPtkvzIII & \aTagPtkvzIV & \aTagPtkvzV & \aTagPtkvzVI & \aTagPtkvzVII & \aTagPtkvzVIII \tabularnewline
VAFIN & \aTagVafin & \aTagVafinAll & \aTagVafinI & \aTagVafinII & \aTagVafinIII & \aTagVafinIV & \aTagVafinV & \aTagVafinVI & \aTagVafinVII & \aTagVafinVIII \tabularnewline
VVFIN & \aTagVvfin & \aTagVvfinAll & \aTagVvfinI & \aTagVvfinII & \aTagVvfinIII & \aTagVvfinIV & \aTagVvfinV & \aTagVvfinVI & \aTagVvfinVII & \aTagVvfinVIII \tabularnewline
VVINF & \aTagVvinf & \aTagVvinfAll & \aTagVvinfI & \aTagVvinfII & \aTagVvinfIII & \aTagVvinfIV & \aTagVvinfV & \aTagVvinfVI & \aTagVvinfVII & \aTagVvinfVIII \tabularnewline
VVPP & \aTagVvpp & \aTagVvppAll & \aTagVvppI & \aTagVvppII & \aTagVvppIII & \aTagVvppIV & \aTagVvppV & \aTagVvppVI & \aTagVvppVII & \aTagVvppVIII \tabularnewline
\bottomrule
\end{tabular}
\end{table*}


\subsubsection*{Syntactic dependency (\texttt{dep})}
A word's column entry provides information about a word's syntactic dependency. Information following the TIGER Treebank annotation scheme \citep{brants2004tiger} is given in the format:
"arc label;word's head;word's child1, word's child2, ..." where the "arc label" (s. table \ref{tab:dep}) describes the type of syntactic relation that connects a "child" (the single word) to its "head".

\begin{table*}[t]
\caption{Syntactic dependencies (DEP). The 15 most often occuring labels (overall 37 labels) sorted alphabetically. Descriptions were taken from spaCy.explain().}
\label{tab:dep}
\begin{tabular}{lllllllllll}
\toprule
\textbf{label} & \textbf{description} & \textbf{all} & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5} & \textbf{6} & \textbf{7} & \textbf{8} \\
\midrule
cd & \aDepCd & \aDepCdAll & \aDepCdI & \aDepCdII & \aDepCdIII & \aDepCdIV & \aDepCdV & \aDepCdVI & \aDepCdVII & \aDepCdVIII \tabularnewline
cj & \aDepCj & \aDepCjAll & \aDepCjI & \aDepCjII & \aDepCjIII & \aDepCjIV & \aDepCjV & \aDepCjVI & \aDepCjVII & \aDepCjVIII \tabularnewline
cp & \aDepCp & \aDepCpAll & \aDepCpI & \aDepCpII & \aDepCpIII & \aDepCpIV & \aDepCpV & \aDepCpVI & \aDepCpVII & \aDepCpVIII \tabularnewline
da & \aDepDa & \aDepDaAll & \aDepDaI & \aDepDaII & \aDepDaIII & \aDepDaIV & \aDepDaV & \aDepDaVI & \aDepDaVII & \aDepDaVIII \tabularnewline
ju & \aDepJu & \aDepJuAll & \aDepJuI & \aDepJuII & \aDepJuIII & \aDepJuIV & \aDepJuV & \aDepJuVI & \aDepJuVII & \aDepJuVIII \tabularnewline
mnr & \aDepMnr & \aDepMnrAll & \aDepMnrI & \aDepMnrII & \aDepMnrIII & \aDepMnrIV & \aDepMnrV & \aDepMnrVI & \aDepMnrVII & \aDepMnrVIII \tabularnewline
mo & \aDepMo & \aDepMoAll & \aDepMoI & \aDepMoII & \aDepMoIII & \aDepMoIV & \aDepMoV & \aDepMoVI & \aDepMoVII & \aDepMoVIII \tabularnewline
nk & \aDepNk & \aDepNkAll & \aDepNkI & \aDepNkII & \aDepNkIII & \aDepNkIV & \aDepNkV & \aDepNkVI & \aDepNkVII & \aDepNkVIII \tabularnewline
oa & \aDepOa & \aDepOaAll & \aDepOaI & \aDepOaII & \aDepOaIII & \aDepOaIV & \aDepOaV & \aDepOaVI & \aDepOaVII & \aDepOaVIII \tabularnewline
oc & \aDepOc & \aDepOcAll & \aDepOcI & \aDepOcII & \aDepOcIII & \aDepOcIV & \aDepOcV & \aDepOcVI & \aDepOcVII & \aDepOcVIII \tabularnewline
pd & \aDepPd & \aDepPdAll & \aDepPdI & \aDepPdII & \aDepPdIII & \aDepPdIV & \aDepPdV & \aDepPdVI & \aDepPdVII & \aDepPdVIII \tabularnewline
pnc & \aDepPnc & \aDepPncAll & \aDepPncI & \aDepPncII & \aDepPncIII & \aDepPncIV & \aDepPncV & \aDepPncVI & \aDepPncVII & \aDepPncVIII \tabularnewline
ROOT & root of sentence & \aDepRootAll & \aDepRootI & \aDepRootII & \aDepRootIII & \aDepRootIV & \aDepRootV & \aDepRootVI & \aDepRootVII & \aDepRootVIII \tabularnewline
sb & \aDepSb & \aDepSbAll & \aDepSbI & \aDepSbII & \aDepSbIII & \aDepSbIV & \aDepSbV & \aDepSbVI & \aDepSbVII & \aDepSbVIII \tabularnewline
svp & separable verb prefix & \aDepSvpAll & \aDepSvpI & \aDepSvpII & \aDepSvpIII & \aDepSvpIV & \aDepSvpV & \aDepSvpVI & \aDepSvpVII & \aDepSvpVIII \tabularnewline
\bottomrule
\end{tabular}
\end{table*}


\subsubsection*{Lemmatization (\texttt{lemma})}
For single words, the base form (root) of the word

\subsubsection*{Common Word (\texttt{stop})}
For single words, this column provides information if the word is part of a stop list, hence one of the most common words in the German language ("True") or not ('"False")?

\subsubsection*{Narrator's descriptive nouns (\texttt{descr})}
A categorizing of nouns that serve as auditory cues about the movie's visual content. Comprised categories focus on the cinematographic scene's environment (geo, geo-room; setting\_new, setting\_old), inherent persons (female, female name; male, male name, person), their appearance (face, head; body, bodypart), and objects (object, furniture).

\subsubsection*{Word embedding (semantic similarity) (\texttt{vector})}
A word's column entry contains a 300-dimensional \href{https://en.wikipedia.org/wiki/Word2vec}{word vector} providing a multi-dimensional meaning representation of the word. Uncommon and out-of-vocabulary words with a vector consisting of 300 dimensions of 0's were set to '\#' [to save space].

\subsubsection*{Phonemes (\texttt{phones})}
Phonemes of German words follow the Prosodylab PhoneSet, English words follow the ARPAbet PhoneSet.

\subsection*{Dataset content}
% habe folgend die Art und Weise aus der Datei p.tex der Schnitt-Annotation übernommen, wobei das im veröffentlichten Paper ganz anders aussieht
% noch mit so Boxen und doi's
% ACHTUNG: github erlaubt laut datalad handbook keine Dateien >100MB
% Anno im Praat Format ist >200MB (und die audiodateien ohnehin)
The released annotation comes in two different versions. First, in a (text-based) .TextGrid file that can be loaded into Praat (\texttt{annotation/fg\_rscut\_ad\_ger\_speech\_tagged.TextGrid}).
Second, as a text-based tab-separated-value (TSV) formatted table  (\texttt{annotation/fg\_rscut\_ad\_ger\_speech\_tagged.tsv})  in accordance with the brain imaging data structure BIDS \citep{gorgolewski2016bids} (\href{https://bids.neuroimaging.io/}{bids.neuroimaging.io}). The source code for all descriptive statistics included in this paper is available in \texttt{code/descriptive-statistics.py} (Python script).

\section*{Dataset validation}
% Information about any validation carried out and/or any limitations of the
% datasets, including any allowances made for controlling bias or unwanted
% sources of variability.
% ~170 words => das wird beim folgenden Schreiben definitiv nichts werden
% Intro
In order to assess data quality, we investigated if contrasting speech-related events to non-speech related events lead to increased activation in areas known to be involved in semantic processing \citep{binder2009semantic, dewitt2012phoneme}.
Moreover, we tested if similar linguistic concepts providing high semantic information (proper nouns and nouns) contrasted to a concept providing low semantic information (conjunctions) lead to increased activation in congruent brain areas.
% Preprocessing
% die Daten aus Hanke2014 sind eigentlich nicht bewegungskorrigiert und aligned
% Quelle ist in vorliegendem Falle:
% juseless.inm7.de:/data/project/studyforrest/collection/phase1
% bei allem, was folgend mit alignment/co-registration zu tun hat, bin ich mir nicht sicher
We used fMRI BOLD data of the 2h audio-description (7 Tesla, 2s TR, partial
brain coverage with 1.4 mm isotropic voxels) \citep{hanke2014audiomovie} that
were already corrected for motion and aligned [wie?] to study specific group template [co-registered to MNI?].
All further steps analysis steps were carried out using Feat v6.00 (FMRI Expert
Analysis Tool)\citep{woolrich2001autocorr} as part of FSL v5.0.9 (FMRIB’s
Software Library)\citep{smith2004fsl}. Data were temporally high-pass filtered (cut-off 150s), spatially smoothed (Gaussian kernel; 4.0 mm FWHM), and the brain was extracted from surrounding tissue [keine Plan, ob die Reihenfolge so korrek ist]. A grand-mean intensity normalization of the entire 4D dataset was performed by a single multiplicative factor.
We implemented a standard three-level, voxel-wise general linear model (GLM) to average parameter estimates across the eight stimulus segments, and later across 19 subjects.

\begin{table*}[t]
    \caption{Overview of the 26 regressors for the validation analysis. The first column contains the number of the regressor in the design file of FSL \citep{smith2004fsl}. The 20 most often occuring labels from the detailed part-of speech tagging were used as such. Words belonging to all other labels were pooled to ``tag\_other''. The regressor ``sentence'' contains the end of complete grammatical sentences. The regressor ``phones'' contains the 80 most often occuring phonemes (``n'' with N=6053 to ``IY1'' with N=32). The regressor ``no-sp'' represents moments when no speech was audible. ''fg\_ad\_lrdiff (left-right volume difference) and ``fg\_ad\_rms'' (root mean square loudness) represent low-level auditory nuissance regressors comprising one event for every movie frame (40ms).}
\label{tab:regressors}
\footnotesize
\begin{tabular}{lp{3.5cm}lllllllll}
\toprule
\textbf{label} &  \textbf{description} & \textbf{all} & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5} & \textbf{6} & \textbf{7} & \textbf{8} \\
\midrule
adja & \aTagAdja & \rAdjaAll & \rAdjaI & \rAdjaII & \rAdjaIII & \rAdjaIV & \rAdjaV & \rAdjaVI & \rAdjaVII & \rAdjaVIII \tabularnewline
adjd & \aTagAdjd & \rAdjdAll & \rAdjdI & \rAdjdII & \rAdjdIII & \rAdjdIV & \rAdjdV & \rAdjdVI & \rAdjdVII & \rAdjdVIII \tabularnewline
adv & \aTagAdv & \rAdvAll & \rAdvI & \rAdvII & \rAdvIII & \rAdvIV & \rAdvV & \rAdvVI & \rAdvVII & \rAdvVIII \tabularnewline
appr & \aTagAppr & \rApprAll & \rApprI & \rApprII & \rApprIII & \rApprIV & \rApprV & \rApprVI & \rApprVII & \rApprVIII \tabularnewline
apprart & preposition with article & \rApprartAll & \rApprartI & \rApprartII & \rApprartIII & \rApprartIV & \rApprartV & \rApprartVI & \rApprartVII & \rApprartVIII \tabularnewline
art & \aTagArt & \rArtAll & \rArtI & \rArtII & \rArtIII & \rArtIV & \rArtV & \rArtVI & \rArtVII & \rArtVIII \tabularnewline
kon & \aTagKon & \rKonAll & \rKonI & \rKonII & \rKonIII & \rKonIV & \rKonV & \rKonVI & \rKonVII & \rKonVIII \tabularnewline
ne & \aTagNe & \rNeAll & \rNeI & \rNeII & \rNeIII & \rNeIV & \rNeV & \rNeVI & \rNeVII & \rNeVIII \tabularnewline
nn & \aTagNn & \rNnAll & \rNnI & \rNnII & \rNnIII & \rNnIV & \rNnV & \rNnVI & \rNnVII & \rNnVIII \tabularnewline
pds & substituting demonstrative pronoun & \rPdsAll & \rPdsI & \rPdsII & \rPdsIII & \rPdsIV & \rPdsV & \rPdsVI & \rPdsVII & \rPdsVIII \tabularnewline
pis & substituting indefinite pronoun & \rPisAll & \rPisI & \rPisII & \rPisIII & \rPisIV & \rPisV & \rPisVI & pper \rPisVII & \rPisVIII \tabularnewline
pper & \aTagPper & \rPperAll & \rPperI & \rPperII & \rPperIII & \rPperIV & \rPperV & \rPperVI & \rPperVII & \rPperVIII \tabularnewline
pposat & \aTagPposat & \rPposatAll & \rPposatI & \rPposatII & \rPposatIII & \rPposatIV & \rPposatV & \rPposatVI & \rPposatVII & \rPposatVIII \tabularnewline
prf & reflexive personal pronoun & \rPrfAll & \rPrfI & \rPrfII & \rPrfIII & \rPrfIV & \rPrfV & \rPrfVI & \rPrfVII & \rPrfVIII \tabularnewline
ptkvz & \aTagPtkvz & \rPtkvzAll & \rPtkvzI & \rPtkvzII & \rPtkvzIII & \rPtkvzIV & \rPtkvzV & \rPtkvzVI & \rPtkvzVII & \rPtkvzVIII \tabularnewline
vafin & \aTagVafin & \rVafinAll & \rVafinI & \rVafinII & \rVafinIII & \rVafinIV & \rVafinV & \rVafinVI & \rVafinVII & \rVafinVIII \tabularnewline
vmfin & finite verb, modal & \rVmfinAll & \rVmfinI & \rVmfinII & \rVmfinIII & \rVmfinIV & \rVmfinV & \rVmfinVI & \rVmfinVII & \rVmfinVIII \tabularnewline
vvfin & \aTagVvfin & \rVvfinAll & \rVvfinI & \rVvfinII & \rVvfinIII & \rVvfinIV & \rVvfinV & \rVvfinVI & \rVvfinVII & \rVvfinVIII \tabularnewline
vvinf & \aTagVvinf & \rVvinfAll & \rVvinfI & \rVvinfII & \rVvinfIII & \rVvinfIV & \rVvinfV & \rVvinfVI & \rVvinfVII & \rVvinfVIII \tabularnewline
vvpp & \aTagVvpp & \rVvppAll & \rVvppI & \rVvppII & \rVvppIII & \rVvppIV & \rVvppV & \rVvppVI & \rVvppVII & \rVvppVIII \tabularnewline
tag\_other & all other TAG categories & \rTagotherAll & \rTagotherI & \rTagotherII & \rTagotherIII & \rTagotherIV & \rTagotherV & \rTagotherVI & \rTagotherVII & \rTagotherVIII \tabularnewline
%e{1-12}
sentence & complete grammatical sentences & \rSentenceAll & \rSentenceI & \rSentenceII & \rSentenceIII & \rSentenceIV & \rSentenceV & \rSentenceVI & \rSentenceVII & \rSentenceVIII \tabularnewline
phones & 80 most often occuring phonemes & \rPhonesAll & \rPhonesI & \rPhonesII & \rPhonesIII & \rPhonesIV & \rPhonesV & \rPhonesVI & \rPhonesVII & \rPhonesVIII \tabularnewline
no-sp & no-speech (``soundscape'') & \rNospAll & \rNospI & \rNospII & \rNospIII & \rNospIV & \rNospV & \rNospVI & \rNospVII & \rNospVIII \tabularnewline
%e{1-12}
fg\_ad\_lrdiff & left-right volume difference & \rFgadlrdiffAll & \rFgadlrdiffI & \rFgadlrdiffII & \rFgadlrdiffIII & \rFgadlrdiffIV & \rFgadlrdiffV & \rFgadlrdiffVI & \rFgadlrdiffVII & \rFgadlrdiffVIII \tabularnewline
fg\_ad\_rms & root mean square & \rFgadrmsAll & \rFgadrmsI & \rFgadrmsII & \rFgadrmsIII & \rFgadrmsIV & \rFgadrmsV & \rFgadrmsVI & \rFgadrmsVII & \rFgadrmsVIII \tabularnewline
\bottomrule
\end{tabular}
\todo[inline]{I think this table doesn't talk about 'regressors'. It talks about the
events that were selected/available to build GLM regressors from them. Hence the term
'event' should be used here, and cross-reference to figure \ref{fig:reg} should be made}
\todo[inline]{what does e1-12 stand for? It makes the label column too wide}
\end{table*}



% 1st lvl
At the first level analysing each segment for each subject individually, we defined 26 regressors (s. table \ref{tab:regressors})
 based on information drawn from the annotation. The 20 most often occuring detailed tag labels (``nn'' with N=\rNnAll\space to ``prf'' with N=\rPrfAll) were modelled as such from the onset to offset of each word. The remaining tags were pooled to a single regressor (``tag\_other``; N=\rTagotherAll). The top 80 phonemes (``n'' with n=6053 to ``IY1'' with N=32) were pooled to the regressor ``phonemes'' (N=\rPhonesAll).
The ends of (complete) grammatical sentences were used as the onset of events, abitrarily lasting 0.2s, for the regressors ``sentence'' (N=\rSentenceAll).
A ``no-speech'' regressor (``no-sp''; N=\rNospAll) serving as a control condition was created by the following rationale: events were fitted into intervals between onsets and offsets of sentences/words assumed to contain no comprehensible speech. Each event of the no-speech condition had a minimum distance of 1.8s to onset/offsets of sentences/words and to each other onset of the no-speech condition (s. anno2events-files.py). A length of 0.07s was chosen for these events matching the average length of phonemes.
Two regressors reflecting auditory (low-level) features (left-right loudness/volume/amplitude difference; root mean squared amplitude) aligned to the frame rate of (40 ms) were modelled to reduce nuisance effects.
Hier (und das ggf auch mehr auf Korrelation der Regressoren eingehen. \ref{fig:reg-corr}).
Those 26 regressors were convolved with FSL's ``Double-Gamma HRF'' as a model of the hemodynamic response function. Temporal derivatives were also included in the design matrix, and it was subjected to the same temporal filtering as the BOLD time series. Finally, six motion parameters were used as additional nuisance regressors.
The following six t-contrasts were defined: 1) words (21 tag-related regressors) > no-speech; 2) no-speech > all 21 tag-related regressors; 3) proper nouns (``ne''; N=\rNeAll) > coordinate conjunctions (``kon''; N=\rKonAll); 4) coordinate conjunctions > proper nouns; 5) nouns (``nn'') > coordinate conjunctions, and 6) coordinate conjunctions > nouns. The first level analysis that fitted each voxel’s time course separately for each subject was performed in functional space preserving the orientation of the EPI images [richtig?].

% Also weshalb wird das temporal filtering der regressoren wann wie gemacht??? -> nachschlagen
% “You should normally apply the same temporal filtering to the model as you have applied to the data, as the model is designed to look like the data before temporal filtering was applied. In this way, long-time-scale components in the model will be dealt with correctly. This is set with the Apply temporal filtering option.”
\begin{figure*}
  \centering
% \includegraphics[width=0.4\textwidth]{frog.jpg}
  \includegraphics[width=\linewidth]{figures/regressor-corr}
  \caption{Pearson correlation coefficients of the 26 regressors used in the analysis to validate the annotation. Regressors were convolved with FSL's ``Double-Gamma HRF'' as a model of the hemodynamic response function, temporally filtered with the same high-pass filter (cut-off 150s) as the BOLD time series, and cocatenated across runs before performing the correlation.}
\label{fig:reg-corr}
\end{figure*}



% 2nd lvl and 3rd lvl
The second-level analysis which averaged contrast estimates across the eight stimulus segments per subject was carried out using a fixed effects model by forcing the random effects variance to zero in FLAME (FMRIB’s Local Analysis of Mixed Effects) \citep{beckmann2003general, woolrich2004multilevel}. The third level analysis which averaged contrast estimates across subjects was carried out using FLAME stage 1 with automatic outlier de-weighting \citep{beckmann2003general, woolrich2004multilevel, woolrich2008robust}.
Z (Gaussianised T/F) statistic images were thresholded using clusters determined by Z>3.4 and a (corrected) cluster significance threshold of p<.05 \citep{woolrich2008robust}. Brain regions associated with observed clusters were determined with the Juelich Histological Atlas \citep{eickhoff2005toolbox,eickhoff2007assignment} the Harvard-Oxford Cortical Atlas \citep{desikan2006automated}[really?] provided by FSL.

% results
% von Interpretation klar(er) getrennt halten
Results: The first contrast that contrasted words to moments where no speech is audible in the audio-description (all 21 tag-related regressors > no-speech) shows\dots;
left lateralization (bigger cluster left in BA XY => Broca)
The contrasts proper nouns > coordinate conjunctions and proper nouns > coordinate conjunctions identify bilateral, largely congruent (?) areas in areas known to be involved in processing auditory stimuli, word, nouns, semantics.

\begin{figure*}
  \centering
% \includegraphics[width=0.4\textwidth]{frog.jpg}
  \includegraphics[width=\linewidth]{figures/slicescolorbars}
  \caption{Mixed-effects group-level (N=14) GLM contrasts for the audio-description of the movie Forrest Gump. All cluster (Z>3.4, p<0.05; cluster corr.; MNI template space).}
  \label{fig:results}
  \todo[inline]{Figure not referenced in the text}
\end{figure*}

\begin{table*}[t]
    \caption{Significant clusters (Z-Threshold Z>3.4; p<.05; corrected) for the contrast words > no-speech.}
\label{tab:cope1}
\begin{tabular}{rrrrrrrrrrp{3cm}}
\toprule
& & & & \multicolumn{3}{r}{max location (MNI)} & \multicolumn{3}{r}{center of gravity (MNI)} &
\\ \cmidrule{5-7} \cmidrule{8-10}
Cl.\-Index & Voxels & $p_{corr.}$ & Z\-max & X & Y & Z  & X & Y & Z & structure \\
\midrule
4 & 14990 & 0 & 6.31 & -49 & -24.7 & 6.35 & -54.8 & -32.5 & 3.73 & AREAL \\
3 & 14469 & 0 & 6.48 & 55 & -14.9 & -6.9 & 54.1 & -23.1 & 0.374 & AREAL \\
2 & 1971 & 2.37E-16 & 5.26 & -51.1 & 25.6 & -10.5 & -53.6 & 17.8 & 10.2 & AREAL \\
1 & 217 & 0.00214 & 4.55 & -4.48 & -13.7 & 10.3 & -6.46 & -14.9 & 9.96 & AREAL \\
\bottomrule
\end{tabular}
  \todo[inline]{Table not referenced in the text}
\end{table*}

\begin{table*}[t]
\caption{Significant clusters (Z-Threshold Z>3.4; p<.05; corrected) for the contrast proper nouns (``ne'') > coordinate conjunctions (``kon'').}
\label{tab:cope3}
\begin{tabular}{rrrrrrrrrrp{3cm}}
\toprule
& & & & \multicolumn{3}{r}{max location (MNI)} & \multicolumn{3}{r}{center of gravity (MNI)} &
\\ \cmidrule{5-7} \cmidrule{8-10}
Cl.\-Index & Voxels & $p_{corr.}$ & Z\-max & X & Y & Z  & X & Y & Z & structure \\
\midrule
9 & 7691 & 2.80E-45 & 6.23 & -61.2 & -22.3 & 11.6 & -55.9 & -20.7 & 4.03 & AREAL \\
8 & 5928 & 5.97E-38 & 5.5 & 57.5 & -26.2 & 15.9 & 58.2 & -15.8 & 3.55 & AREAL \\
7 & 479 & 1.13E-06 & 4.62 & -5.42 & -32.3 & 25.3 & -4.28 & -39.4 & 22.8 & AREAL \\
6 & 420 & 4.65E-06 & 4.85 & -4.76 & -71.4 & 40.1 & -3.74 & -68.5 & 36.2 & AREAL \\
5 & 407 & 6.38E-06 & 5.07 & 6.83 & -40.1 & 24.5 & 6.67 & -38.7 & 23.1 & AREAL \\
4 & 294 & 0.000115 & 4.57 & 17 & -69.1 & 34.6 & 17.7 & -67.1 & 34.9 & AREAL \\
3 & 121 & 0.0237 & 3.95 & 8.12 & -98.2 & 0.359 & 8.75 & -97.7 & -3.15 & AREAL \\
2 & 117 & 0.0274 & 4.38 & 36.9 & -24.8 & 4.55 & 37.4 & -23 & 3.09 & AREAL \\
1 & 115 & 0.0295 & 4.08 & -44.6 & -71.7 & 21.7 & -43.6 & -70.8 & 23.4 & AREAL \\
\bottomrule
\end{tabular}
\todo[inline]{Table not referenced in the text}

\end{table*}


\begin{table*}[t]
    \caption{Significant clusters (Z-Threshold Z>3.4; p<.05; corrected) for the contrast nouns (``nn'') > coordinate conjunctions (``kon'').}
\label{tab:cope5}
\begin{tabular}{rrrrrrrrrrp{3cm}}
\toprule
& & & & \multicolumn{3}{r}{max location (MNI)} & \multicolumn{3}{r}{center of gravity (MNI)} &
\\ \cmidrule{5-7} \cmidrule{8-10}
Cl.\-Index & Voxels & $p_{corr.}$ & Z\-max & X & Y & Z  & X & Y & Z & structure \\
\midrule
4 & 3166 & 2.79E-25 & 5.75 & -61.3 & -10.6 & -2.93 & -57.7 & -14.3 & 1.47 & AREAL \\
3 & 1753 & 7.18E-17 & 4.99 & 63.3 & -15.1 & 8.41 & 58 & -13 & 4.02 & AREAL \\
2 & 166 & 0.00446 & 4.5 & 6.83 & -40.1 & 24.5 & 7.01 & -39.7 & 24.2 & AREAL \\
1 & 149 & 0.00793 & 4.13 & 18.2 & -67.8 & 36 & 19.8 & -66.4 & 34.6 & AREAL \\
\bottomrule
\end{tabular}
\end{table*}


% discussion
% careful what you pretend, check & cite (again)
% \citep{binder2009semantic, dewitt2012phoneme}.
Discussion: alles total awesome; Correlation der (konvolvierten Regressoren) is gut (s. figure \ref{fig:reg-corr}; Ergebnisse ergeben Sinn -> benutzt die Anno for awesome research

\section*{Data availability}
% aus der Schnitt-Annotation übernommen
\texttt{This section will be auto-generated.}

In addition, released data, code, and manuscript sources are also available on
Github (\url{https://github.com/psychoinformatics-de/studyforrest-paper-speechannotation}).

\section*{Conclusions}
% state what you think are the main conclusions that can be realistically drawn from the findings in the paper, taking care not to make claims that cannot be supported.
Conclusion hatten wir bei der Schnitt-Annotation nicht; entspricht im Grunde dem letzten Absatz der Einleitung


\subsection*{Author contributions}
% subsection in Schnitte-Anno
%In order to give appropriate credit to each author of an article, the
%individual contributions of each author to the manuscript should be detailed
%in this section. We recommend using author initials and then stating briefly
%how they contributed.
COH designed, performed, and validated the annotation, and wrote the manuscript.
MH provided critical feedback on the procedure and wrote the manuscript.

\subsection*{Competing interests}
% subsection in Schnitte-Anno
No competing interests were disclosed.

\subsection*{Grant information}

COH was supported by a graduate stipend from the German federal state of
Saxony-Anhalt and MH was supported by funds from the German federal state of
Saxony-Anhalt and the European Regional Development Fund (ERDF), Project:
Center for Behavioral Brain Sciences (CBBS). Work on the adapting data
management technology for this study was in part supported by the European
Union’s Horizon 2020 Research and Innovation Programme under Grant Agreement
no. 785907 (HBP SGA2).


\subsection*{Acknowledgements}
We are grateful to \href{www.florianschurz.de}{Florian Schurz} who initiated doing the annotation of the descriptive nouns, and performed the preliminary annotation of nouns. Christian O. Häusler is also grateful to Valeri Kippes who took care of the author's mental sanity by providing excellent training at his gym in Jülich during the mentally draining period of manual corrections of the annotation.

{\small\bibliographystyle{unsrtnat}
\bibliography{references}}

\clearpage
% der alte Entwurf der Tabelle; hier mit rules/description in der Tabelle
\begin{center}
\begin{tabular}{ |c|c|c|c| }
\hline
category & description & examples & count\\
\hline
geo & immobile landmarks & building, tree, street, alley, meadow, cornfield, river & 125\\
geo-room & rooms / locales; elements defining a locale's spatial layout & living room; wall, door, window, floor, turf & 105\\
setting\_new & first-time mentioned setting & on a bridge, on an alley, on campus & 86\\
setting\_rec & recurring setting & at the bus stop & 37\\
body & trunk of the body; overlaid clothes & back, hip, shoulder; jacket, dress, shirt & 66\\
bodypart & limbs and trousers & arm, finger, leg, toe & 69\\
face & face or parts of it & face, ear, nose, mouth & 47\\
head & non-face parts of the head; worn headgear & head, hair, ear, neck, helmet & 36\\
furniture & movable objects insides/outsides & bench, bed, table, chair & 50\\
object & countable entities with firm boundaries & feather, telephone, car & 232\\
objects & countable entities with firm boundaries & wheels, photos & 52\\
female & female person & nurse, mother, women & 31\\
females & female persons & women & 3\\
fname & female name & Jenny, Carla & 74\\
male & male person & man, father, soldier & 89\\
males & concrete male persons & boys, opponents & 23\\
mname & male name of person present in the scene & Forrest, Bubba, Kennedy & 291\\
persons & concrete persons of unknown sex / gender & hippies, patients & 17\\
++ & nouns, adverbial adjectives, and adverbs & in the evening, it's daytime, later \\
\hline
\label{tab:descr-nouns-old}
\end{tabular}
\todo[inline]{If the descriptive nounes are moved to the PPA paper, this table should be removed}
\end{center}


\end{document}
